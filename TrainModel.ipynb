{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath =  \"../../project_course_data/\"\n",
    "fileName = \"preprocessedDataLabeled.csv\"\n",
    "\n",
    "data = pd.read_csv(filePath + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printRow(df, id):\n",
    "    try:\n",
    "        row = df[df[\"Id\"] == id]\n",
    "        for col, val in row.iloc[0].items():\n",
    "            print(f\"{col}: {val}\")\n",
    "    except KeyError:\n",
    "        print(f\"Row with id {id} not found in DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime: 2023-11-22 12:18:39\n",
      "Label: Unknown\n",
      "Duration: 0.0\n",
      "Packets: 0.0\n",
      "Bytes: 5.82e-05\n",
      "Flows: 1\n",
      "Id: 1\n",
      "Src IP Addr: 13.107.42.18\n",
      "Src Port: 443\n",
      "Dst IP Addr: 192.168.8.235\n",
      "Dst Port: 63935\n",
      "Host IP: 13.107.42.18\n",
      "Client IP: 192.168.8.235\n",
      "Domain Name: 0\n",
      "IGMP: 0\n",
      "TCP: 1\n",
      "UDP: 0\n",
      "Host Port: 443\n",
      "0: 0\n",
      "1900: 0\n",
      "22222: 0\n",
      "27018: 0\n",
      "27025: 0\n",
      "27036: 0\n",
      "27043: 0\n",
      "27047: 0\n",
      "27051: 0\n",
      "27053: 0\n",
      "27057: 0\n",
      "27060: 0\n",
      "3478: 0\n",
      "3480: 0\n",
      "34820: 0\n",
      "3702: 0\n",
      "4070: 0\n",
      "44142: 0\n",
      "443: 1\n",
      "50002: 0\n",
      "50012: 0\n",
      "50022: 0\n",
      "50027: 0\n",
      "5228: 0\n",
      "5353: 0\n",
      "5355: 0\n",
      "67: 0\n",
      "80: 0\n",
      "8009: 0\n",
      "1drv: 0\n",
      "1.00E+100: 0\n",
      "82f3dc: 0\n",
      "833aec: 0\n",
      "a104: 0\n",
      "a184: 0\n",
      "a2: 0\n",
      "a23: 0\n",
      "a95: 0\n",
      "aa784e235de7c8b14: 0\n",
      "adobedc: 0\n",
      "akamaitechnologies: 0\n",
      "all: 0\n",
      "amazonaws: 0\n",
      "ams: 0\n",
      "ams1: 0\n",
      "ams15s47: 0\n",
      "ams15s51: 0\n",
      "ams17s02: 0\n",
      "ams17s04: 0\n",
      "ams17s13: 0\n",
      "ams17s17: 0\n",
      "ams58: 0\n",
      "andreas: 0\n",
      "arn: 0\n",
      "arn001: 0\n",
      "arn04: 0\n",
      "arn09s18: 0\n",
      "arn09s19: 0\n",
      "arn09s20: 0\n",
      "arn09s21: 0\n",
      "arn09s22: 0\n",
      "arn09s23: 0\n",
      "arn09s25: 0\n",
      "arn09s26: 0\n",
      "arn09s27: 0\n",
      "arn1: 0\n",
      "arn11s03: 0\n",
      "arn11s04: 0\n",
      "arn11s09: 0\n",
      "arn11s10: 0\n",
      "arn11s11: 0\n",
      "arn11s12: 0\n",
      "arn11s13: 0\n",
      "arn11s14: 0\n",
      "arn2: 0\n",
      "arn54: 0\n",
      "arn56: 0\n",
      "awsglobalaccelerator: 0\n",
      "bc: 0\n",
      "berlin: 0\n",
      "betterttv: 0\n",
      "bkk03s02: 0\n",
      "bl: 0\n",
      "bunnyinfra: 0\n",
      "c061: 0\n",
      "c062: 0\n",
      "c063: 0\n",
      "c064: 0\n",
      "c066: 0\n",
      "c069: 0\n",
      "c073: 0\n",
      "c076: 0\n",
      "c078: 0\n",
      "c079: 0\n",
      "c081: 0\n",
      "c082: 0\n",
      "c083: 0\n",
      "c084: 0\n",
      "c085: 0\n",
      "c086: 0\n",
      "c087: 0\n",
      "c089: 0\n",
      "c090: 0\n",
      "c091: 0\n",
      "c093: 0\n",
      "c094: 0\n",
      "c095: 0\n",
      "c096: 0\n",
      "c097: 0\n",
      "c098: 0\n",
      "c099: 0\n",
      "c100: 0\n",
      "c101: 0\n",
      "c102: 0\n",
      "c103: 0\n",
      "c104: 0\n",
      "c105: 0\n",
      "c107: 0\n",
      "c108: 0\n",
      "c109: 0\n",
      "c110: 0\n",
      "cdn: 0\n",
      "cds260: 0\n",
      "cds456: 0\n",
      "cds822: 0\n",
      "cds848: 0\n",
      "ced348: 0\n",
      "ced64c: 0\n",
      "ced690: 0\n",
      "ced6a0: 0\n",
      "ced6d0: 0\n",
      "ced7f4: 0\n",
      "central: 0\n",
      "clients: 0\n",
      "cloudfront: 0\n",
      "com: 0\n",
      "compute: 0\n",
      "cph2: 0\n",
      "data: 0\n",
      "dc: 0\n",
      "de: 0\n",
      "deploy: 0\n",
      "dfw25s48: 0\n",
      "dgw: 0\n",
      "dittrich: 0\n",
      "e2a: 0\n",
      "e37: 0\n",
      "east: 0\n",
      "ec2: 0\n",
      "ed0: 0\n",
      "ed13: 0\n",
      "ed14: 0\n",
      "ed2: 0\n",
      "edge: 0\n",
      "elektroroyal: 0\n",
      "eu: 0\n",
      "ev: 0\n",
      "f1: 0\n",
      "f10: 0\n",
      "f101: 0\n",
      "f113: 0\n",
      "f13: 0\n",
      "f138: 0\n",
      "f14: 0\n",
      "f163: 0\n",
      "f164: 0\n",
      "f17: 0\n",
      "f170: 0\n",
      "f188: 0\n",
      "f19: 0\n",
      "f2: 0\n",
      "f22: 0\n",
      "f27: 0\n",
      "f3: 0\n",
      "f4: 0\n",
      "f6: 0\n",
      "f7: 0\n",
      "f8: 0\n",
      "f84: 0\n",
      "f9: 0\n",
      "f94: 0\n",
      "facebook: 0\n",
      "fbcdn: 0\n",
      "forum: 0\n",
      "fra: 0\n",
      "fra07s64: 0\n",
      "fra16s58: 0\n",
      "fra16s61: 0\n",
      "fra60: 0\n",
      "github: 0\n",
      "google: 0\n",
      "googleusercontent: 0\n",
      "gru10s11: 0\n",
      "hkg12s26: 0\n",
      "https: 0\n",
      "iad23s04: 0\n",
      "iad23s94: 0\n",
      "iad30s43: 0\n",
      "identrust: 0\n",
      "igmp: 0\n",
      "in: 0\n",
      "info: 0\n",
      "instagram: 0\n",
      "ip: 0\n",
      "ipv4: 0\n",
      "ix: 0\n",
      "jfk1: 0\n",
      "justin: 0\n",
      "kairos: 0\n",
      "kul09s13: 0\n",
      "lb: 0\n",
      "le: 0\n",
      "lf: 0\n",
      "lg: 0\n",
      "li: 0\n",
      "lk: 0\n",
      "llnw: 0\n",
      "lo: 0\n",
      "lq: 0\n",
      "lr: 0\n",
      "lt: 0\n",
      "lu: 0\n",
      "maa05s26: 0\n",
      "mail: 0\n",
      "main: 0\n",
      "mcast: 0\n",
      "mdns: 0\n",
      "mil04s51: 0\n",
      "mini: 0\n",
      "ms: 0\n",
      "msedge: 0\n",
      "muc03s13: 0\n",
      "mysnip: 0\n",
      "net: 0\n",
      "netonnet: 0\n",
      "nflxvideo: 0\n",
      "no600: 0\n",
      "north: 0\n",
      "ns3048892: 0\n",
      "oca: 0\n",
      "olio: 0\n",
      "org: 0\n",
      "p3: 0\n",
      "p42: 0\n",
      "portsit: 0\n",
      "redirect: 0\n",
      "routers: 0\n",
      "sdr1: 0\n",
      "se: 0\n",
      "server: 0\n",
      "server1: 0\n",
      "shv: 0\n",
      "sockets: 0\n",
      "star: 0\n",
      "static: 0\n",
      "sto: 0\n",
      "svn: 0\n",
      "svt: 0\n",
      "syd15s05: 0\n",
      "tbcn: 0\n",
      "telia: 0\n",
      "travel: 0\n",
      "tv: 0\n",
      "us: 0\n",
      "valve: 0\n",
      "vergic: 0\n",
      "video: 0\n",
      "web03: 0\n",
      "west: 0\n",
      "www: 0\n",
      "xx: 0\n",
      "ym: 0\n",
      "your: 0\n",
      "yul03s05: 0\n",
      "AIBV: 0\n",
      "AKAMAI: 0\n",
      "AKAMAI-PA: 0\n",
      "AMAZO-CF: 0\n",
      "AMAZO-ZDUB4: 0\n",
      "AMAZO-ZFRA: 0\n",
      "AMAZO-ZIAD4: 0\n",
      "AMAZO-ZL4: 0\n",
      "AMAZO-ZPDX: 0\n",
      "AMAZO-ZPDX2: 0\n",
      "AMAZO-ZPDX3: 0\n",
      "AMAZO-ZPDX4: 0\n",
      "AMAZO-ZPDX6: 0\n",
      "AMAZO-ZPDX8: 0\n",
      "AMAZO-ZPDX9: 0\n",
      "AMAZON: 0\n",
      "AMAZON-2011L: 0\n",
      "AMAZON-ARN: 0\n",
      "AMAZON-CF: 0\n",
      "AMAZON-DUB: 0\n",
      "AMAZON-EC2-8: 0\n",
      "AMAZON-FRA: 0\n",
      "AMAZON-IAD: 0\n",
      "AMAZON-LHR: 0\n",
      "AMAZON-ZPDX: 0\n",
      "AS-CLOUD-ENGINEERING: 0\n",
      "AT-88-Z: 0\n",
      "AUTOMATTIC: 0\n",
      "BLS-68-219-0-0-1003020945: 0\n",
      "CDN77-STOCKHOLM-2: 0\n",
      "CLOUDFLARENET: 0\n",
      "CLOUDFLARENET-EU: 0\n",
      "DE-HETZNER-20010209: 0\n",
      "ECN-NETWORK: 0\n",
      "EDGECAST-NETBLK-04: 0\n",
      "EDGECAST-NETBLK-08: 0\n",
      "EU-VC-IP4-7: 0\n",
      "GITHU: 0\n",
      "GOOGL-2: 0\n",
      "GOOGLE: 0\n",
      "GOOGLE-CLOUD: 0\n",
      "IE-FACEBOOK-20110418: 0\n",
      "INCAPSULA-NET: 0\n",
      "LC-ORG-ARIN-BLK3: 0\n",
      "LVLT-ORG-8-8: 0\n",
      "MICROSOFT: 0\n",
      "MSFT: 1\n",
      "NETFLIX-SS-3: 0\n",
      "NON-NET: 0\n",
      "NVIDIA-NGN-GB: 0\n",
      "OVH-ARIN-7: 0\n",
      "PACKET-NET-192-20: 0\n",
      "SD-ERI-lon1-eri1-sdagg30ab-n93-2-2: 0\n",
      "SE-AKAMAI: 0\n",
      "SE-BEEBYTE-20190313: 0\n",
      "SE-Cygate-DC-CUSTOMERS: 0\n",
      "SE-GLE-RIPE-20101103: 0\n",
      "SE-PORTS-NET2: 0\n",
      "SKYCA-3: 0\n",
      "SLC-IP-ADDRESS-RANGES: 0\n",
      "SS-CDN-4: 0\n",
      "SVT-DIST-101: 0\n",
      "SVT-DIST-103: 0\n",
      "TELIANET: 0\n",
      "THEFA-3: 0\n",
      "TWITCH: 0\n",
      "US-GITHUB-20170413: 0\n",
      "US-LLNW-20050822: 0\n",
      "US-LLNW-20090402: 0\n",
      "US-LLNW-20100512: 0\n",
      "VALVE-L1: 0\n",
      "VALVE-V4-6: 0\n",
      "VC-AP: 0\n",
      "VZ: 0\n",
      "discord-sesto2-1: 0\n",
      "CA: 0\n",
      "DE: 0\n",
      "FR: 0\n",
      "GB: 0\n",
      "IE: 0\n",
      "NL: 0\n",
      "SE: 0\n",
      "SG: 0\n",
      "US: 1\n"
     ]
    }
   ],
   "source": [
    "id = 1\n",
    "printRow(data, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop uninteresting attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDropped = data.copy()\n",
    "\n",
    "dataDropped = dataDropped.drop(dataDropped[dataDropped.Label == \"Unknown\"].index)\n",
    "\n",
    "attributesToDrop = [\"Id\" ,\"Domain Name\", \"Flows\", \"Datetime\", \"Host Port\", \"Src IP Addr\", \"Dst IP Addr\", \"Client IP\", \"Host IP\", \"Src Port\", \"Dst Port\"]\n",
    "dataDropped = dataDropped.drop(attributesToDrop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with id 1 not found in DataFrame.\n"
     ]
    }
   ],
   "source": [
    "printRow(dataDropped, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Service label into integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LABELS AND CORRESPONDING NUMBER:\n",
      "0\tYoutube\n",
      "1\tNetflix\n",
      "2\tBrowsing/Shopping\n",
      "3\tTwitch TV\n",
      "4\tPrime Video\n",
      "5\tSVT Play\n",
      "6\tSpotify\n",
      "7\tFacebook\n",
      "8\tPlaystation\n",
      "9\tSoundcloud\n",
      "10\tDiscord\n",
      "11\tReddit\n",
      "12\tAmazon SHOP\n",
      "13\tGoogle Drive\n",
      "14\tSkype\n",
      "15\tDisney+\n",
      "16\tSteam Gaming\n",
      "17\tGmail\n",
      "18\tInstagram\n",
      "19\tOutlook Mail\n",
      "20\tX\n"
     ]
    }
   ],
   "source": [
    "dataNumLabel = dataDropped.copy()\n",
    "\n",
    "n = dataNumLabel[\"Label\"].value_counts()\n",
    "\n",
    "LABELS_DICT = {}\n",
    "for i in range(len(n)):\n",
    "    LABELS_DICT[n.index.tolist()[i]] = i\n",
    "print()\n",
    "print(\"LABELS AND CORRESPONDING NUMBER:\")\n",
    "for key,val in LABELS_DICT.items():\n",
    "    print(f\"{val}\\t{key}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion functions for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2num(label):\n",
    "    return(LABELS_DICT[label])\n",
    "def num2label(num):\n",
    "    return next((key for key, val in LABELS_DICT.items() if val == num), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data from the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataNumLabel.drop(\"Label\", axis = 1).astype(\"float32\").to_numpy()\n",
    "Y = dataNumLabel[\"Label\"].apply(label2num).to_numpy() #translate label to corresponding integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainging data and Testing data split & convert into tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN TEST SPLIT\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state=13)\n",
    " \n",
    "# TO TENSOR\n",
    "Xtrain = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "Ytrain = torch.tensor(Ytrain, dtype=torch.long)\n",
    "Xtest = torch.tensor(Xtest, dtype=torch.float32)\n",
    "Ytest = torch.tensor(Ytest, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK CLASS\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, h1, h2, h3, h4, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        dropoutrate = 0.5\n",
    "        self.fc1 = nn.Linear(input_size, h1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropoutrate)\n",
    "\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropoutrate)\n",
    "\n",
    "        self.fc4 = nn.Linear(h3, h4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "\n",
    "        self.fc5 = nn.Linear(h4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        x = self.relu4(x)\n",
    "\n",
    "        x = self.fc5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NETWORK LAYER SIZES\n",
    "input_size = X.shape[1]\n",
    "h1 = 200\n",
    "h2 = 150\n",
    "h3 = 100\n",
    "h4 = 50\n",
    "output_size = len(LABELS_DICT)\n",
    "\n",
    "# CREATE NEURAL NETWORK MODEL\n",
    "model = Net(input_size, h1, h2, h3, h4, output_size)\n",
    "\n",
    "# LOSS & EVALUATION\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001) #create optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Loss: 0.849406361579895\n",
      "Epoch [2/500], Loss: 0.8498115539550781\n",
      "Epoch [3/500], Loss: 0.8508362770080566\n",
      "Epoch [4/500], Loss: 0.8517848253250122\n",
      "Epoch [5/500], Loss: 0.8512610793113708\n",
      "Epoch [6/500], Loss: 0.8497948050498962\n",
      "Epoch [7/500], Loss: 0.8486401438713074\n",
      "Epoch [8/500], Loss: 0.8488523364067078\n",
      "Epoch [9/500], Loss: 0.8499324321746826\n",
      "Epoch [10/500], Loss: 0.8502976298332214\n",
      "Epoch [11/500], Loss: 0.8498690724372864\n",
      "Epoch [12/500], Loss: 0.8487566113471985\n",
      "Epoch [13/500], Loss: 0.84803307056427\n",
      "Epoch [14/500], Loss: 0.8484055995941162\n",
      "Epoch [15/500], Loss: 0.8492395281791687\n",
      "Epoch [16/500], Loss: 0.8496139049530029\n",
      "Epoch [17/500], Loss: 0.8493883609771729\n",
      "Epoch [18/500], Loss: 0.8494486212730408\n",
      "Epoch [19/500], Loss: 0.8500787019729614\n",
      "Epoch [20/500], Loss: 0.85160893201828\n",
      "Epoch [21/500], Loss: 0.8512500524520874\n",
      "Epoch [22/500], Loss: 0.8507909774780273\n",
      "Epoch [23/500], Loss: 0.8491981625556946\n",
      "Epoch [24/500], Loss: 0.8481243252754211\n",
      "Epoch [25/500], Loss: 0.8477984070777893\n",
      "Epoch [26/500], Loss: 0.8481471538543701\n",
      "Epoch [27/500], Loss: 0.8488606214523315\n",
      "Epoch [28/500], Loss: 0.8490405678749084\n",
      "Epoch [29/500], Loss: 0.8484678864479065\n",
      "Epoch [30/500], Loss: 0.8474084138870239\n",
      "Epoch [31/500], Loss: 0.8467459678649902\n",
      "Epoch [32/500], Loss: 0.8469585180282593\n",
      "Epoch [33/500], Loss: 0.8474992513656616\n",
      "Epoch [34/500], Loss: 0.8473399877548218\n",
      "Epoch [35/500], Loss: 0.8463654518127441\n",
      "Epoch [36/500], Loss: 0.8456429839134216\n",
      "Epoch [37/500], Loss: 0.8456766605377197\n",
      "Epoch [38/500], Loss: 0.8462763428688049\n",
      "Epoch [39/500], Loss: 0.8465479612350464\n",
      "Epoch [40/500], Loss: 0.84650719165802\n",
      "Epoch [41/500], Loss: 0.8460069298744202\n",
      "Epoch [42/500], Loss: 0.8458621501922607\n",
      "Epoch [43/500], Loss: 0.8461345434188843\n",
      "Epoch [44/500], Loss: 0.8464718461036682\n",
      "Epoch [45/500], Loss: 0.8464588522911072\n",
      "Epoch [46/500], Loss: 0.8459899425506592\n",
      "Epoch [47/500], Loss: 0.8453192114830017\n",
      "Epoch [48/500], Loss: 0.8452117443084717\n",
      "Epoch [49/500], Loss: 0.8452368378639221\n",
      "Epoch [50/500], Loss: 0.8453923463821411\n",
      "Epoch [51/500], Loss: 0.845578134059906\n",
      "Epoch [52/500], Loss: 0.8457074165344238\n",
      "Epoch [53/500], Loss: 0.8451627492904663\n",
      "Epoch [54/500], Loss: 0.8443282842636108\n",
      "Epoch [55/500], Loss: 0.8437268733978271\n",
      "Epoch [56/500], Loss: 0.8438954949378967\n",
      "Epoch [57/500], Loss: 0.8443282842636108\n",
      "Epoch [58/500], Loss: 0.8445374369621277\n",
      "Epoch [59/500], Loss: 0.8440911173820496\n",
      "Epoch [60/500], Loss: 0.8435355424880981\n",
      "Epoch [61/500], Loss: 0.8430958986282349\n",
      "Epoch [62/500], Loss: 0.842849612236023\n",
      "Epoch [63/500], Loss: 0.8427565097808838\n",
      "Epoch [64/500], Loss: 0.8428117036819458\n",
      "Epoch [65/500], Loss: 0.8429017663002014\n",
      "Epoch [66/500], Loss: 0.8432731032371521\n",
      "Epoch [67/500], Loss: 0.843576967716217\n",
      "Epoch [68/500], Loss: 0.8441138863563538\n",
      "Epoch [69/500], Loss: 0.844476044178009\n",
      "Epoch [70/500], Loss: 0.8455127477645874\n",
      "Epoch [71/500], Loss: 0.847700297832489\n",
      "Epoch [72/500], Loss: 0.8521667122840881\n",
      "Epoch [73/500], Loss: 0.8512197136878967\n",
      "Epoch [74/500], Loss: 0.8474075198173523\n",
      "Epoch [75/500], Loss: 0.844141960144043\n",
      "Epoch [76/500], Loss: 0.8452733755111694\n",
      "Epoch [77/500], Loss: 0.847787082195282\n",
      "Epoch [78/500], Loss: 0.8476210832595825\n",
      "Epoch [79/500], Loss: 0.8458663821220398\n",
      "Epoch [80/500], Loss: 0.8440201282501221\n",
      "Epoch [81/500], Loss: 0.843829870223999\n",
      "Epoch [82/500], Loss: 0.8452698588371277\n",
      "Epoch [83/500], Loss: 0.8466477394104004\n",
      "Epoch [84/500], Loss: 0.844157338142395\n",
      "Epoch [85/500], Loss: 0.8422743678092957\n",
      "Epoch [86/500], Loss: 0.8435403108596802\n",
      "Epoch [87/500], Loss: 0.8452602624893188\n",
      "Epoch [88/500], Loss: 0.8445039391517639\n",
      "Epoch [89/500], Loss: 0.8414033055305481\n",
      "Epoch [90/500], Loss: 0.8429625630378723\n",
      "Epoch [91/500], Loss: 0.8455401659011841\n",
      "Epoch [92/500], Loss: 0.8445940613746643\n",
      "Epoch [93/500], Loss: 0.8413326144218445\n",
      "Epoch [94/500], Loss: 0.8423508405685425\n",
      "Epoch [95/500], Loss: 0.8442524075508118\n",
      "Epoch [96/500], Loss: 0.8435049653053284\n",
      "Epoch [97/500], Loss: 0.8414473533630371\n",
      "Epoch [98/500], Loss: 0.8416387438774109\n",
      "Epoch [99/500], Loss: 0.8429712653160095\n",
      "Epoch [100/500], Loss: 0.8422685861587524\n",
      "Epoch [101/500], Loss: 0.8413066864013672\n",
      "Epoch [102/500], Loss: 0.8411813974380493\n",
      "Epoch [103/500], Loss: 0.8412407040596008\n",
      "Epoch [104/500], Loss: 0.8412634134292603\n",
      "Epoch [105/500], Loss: 0.8414202332496643\n",
      "Epoch [106/500], Loss: 0.8409333825111389\n",
      "Epoch [107/500], Loss: 0.840173065662384\n",
      "Epoch [108/500], Loss: 0.8401879072189331\n",
      "Epoch [109/500], Loss: 0.8408170342445374\n",
      "Epoch [110/500], Loss: 0.8406136631965637\n",
      "Epoch [111/500], Loss: 0.8395993709564209\n",
      "Epoch [112/500], Loss: 0.8390763401985168\n",
      "Epoch [113/500], Loss: 0.840160608291626\n",
      "Epoch [114/500], Loss: 0.8401784300804138\n",
      "Epoch [115/500], Loss: 0.8394541144371033\n",
      "Epoch [116/500], Loss: 0.8389151096343994\n",
      "Epoch [117/500], Loss: 0.8392238616943359\n",
      "Epoch [118/500], Loss: 0.8393892049789429\n",
      "Epoch [119/500], Loss: 0.8387309908866882\n",
      "Epoch [120/500], Loss: 0.8382659554481506\n",
      "Epoch [121/500], Loss: 0.8384130597114563\n",
      "Epoch [122/500], Loss: 0.838469386100769\n",
      "Epoch [123/500], Loss: 0.8381662368774414\n",
      "Epoch [124/500], Loss: 0.8378410935401917\n",
      "Epoch [125/500], Loss: 0.8379007577896118\n",
      "Epoch [126/500], Loss: 0.8380419611930847\n",
      "Epoch [127/500], Loss: 0.8381350040435791\n",
      "Epoch [128/500], Loss: 0.8381125330924988\n",
      "Epoch [129/500], Loss: 0.8387560248374939\n",
      "Epoch [130/500], Loss: 0.8395078778266907\n",
      "Epoch [131/500], Loss: 0.8404747843742371\n",
      "Epoch [132/500], Loss: 0.8405253887176514\n",
      "Epoch [133/500], Loss: 0.8400351405143738\n",
      "Epoch [134/500], Loss: 0.8385403752326965\n",
      "Epoch [135/500], Loss: 0.8375599980354309\n",
      "Epoch [136/500], Loss: 0.8373724818229675\n",
      "Epoch [137/500], Loss: 0.8379445672035217\n",
      "Epoch [138/500], Loss: 0.838813066482544\n",
      "Epoch [139/500], Loss: 0.8392232656478882\n",
      "Epoch [140/500], Loss: 0.8389313817024231\n",
      "Epoch [141/500], Loss: 0.8376032710075378\n",
      "Epoch [142/500], Loss: 0.8366276621818542\n",
      "Epoch [143/500], Loss: 0.8368907570838928\n",
      "Epoch [144/500], Loss: 0.8377965092658997\n",
      "Epoch [145/500], Loss: 0.8383081555366516\n",
      "Epoch [146/500], Loss: 0.8379154205322266\n",
      "Epoch [147/500], Loss: 0.8369687795639038\n",
      "Epoch [148/500], Loss: 0.836515486240387\n",
      "Epoch [149/500], Loss: 0.8367248177528381\n",
      "Epoch [150/500], Loss: 0.8373299837112427\n",
      "Epoch [151/500], Loss: 0.8373281955718994\n",
      "Epoch [152/500], Loss: 0.8373333811759949\n",
      "Epoch [153/500], Loss: 0.8368996381759644\n",
      "Epoch [154/500], Loss: 0.8366091251373291\n",
      "Epoch [155/500], Loss: 0.8363583087921143\n",
      "Epoch [156/500], Loss: 0.8360854387283325\n",
      "Epoch [157/500], Loss: 0.8362468481063843\n",
      "Epoch [158/500], Loss: 0.836982250213623\n",
      "Epoch [159/500], Loss: 0.8377200961112976\n",
      "Epoch [160/500], Loss: 0.8372762799263\n",
      "Epoch [161/500], Loss: 0.8360732793807983\n",
      "Epoch [162/500], Loss: 0.8354818224906921\n",
      "Epoch [163/500], Loss: 0.8357347846031189\n",
      "Epoch [164/500], Loss: 0.8361078500747681\n",
      "Epoch [165/500], Loss: 0.8359753489494324\n",
      "Epoch [166/500], Loss: 0.8356454968452454\n",
      "Epoch [167/500], Loss: 0.8358827829360962\n",
      "Epoch [168/500], Loss: 0.8361531496047974\n",
      "Epoch [169/500], Loss: 0.835959255695343\n",
      "Epoch [170/500], Loss: 0.8357751965522766\n",
      "Epoch [171/500], Loss: 0.8366109132766724\n",
      "Epoch [172/500], Loss: 0.8368936777114868\n",
      "Epoch [173/500], Loss: 0.8363993167877197\n",
      "Epoch [174/500], Loss: 0.8352007865905762\n",
      "Epoch [175/500], Loss: 0.8346061110496521\n",
      "Epoch [176/500], Loss: 0.8346124291419983\n",
      "Epoch [177/500], Loss: 0.8349290490150452\n",
      "Epoch [178/500], Loss: 0.8355435729026794\n",
      "Epoch [179/500], Loss: 0.8359906077384949\n",
      "Epoch [180/500], Loss: 0.8357294201850891\n",
      "Epoch [181/500], Loss: 0.8346056342124939\n",
      "Epoch [182/500], Loss: 0.8337523937225342\n",
      "Epoch [183/500], Loss: 0.8338704109191895\n",
      "Epoch [184/500], Loss: 0.834721565246582\n",
      "Epoch [185/500], Loss: 0.835386335849762\n",
      "Epoch [186/500], Loss: 0.8350899815559387\n",
      "Epoch [187/500], Loss: 0.8348076343536377\n",
      "Epoch [188/500], Loss: 0.8346752524375916\n",
      "Epoch [189/500], Loss: 0.8345752358436584\n",
      "Epoch [190/500], Loss: 0.834299623966217\n",
      "Epoch [191/500], Loss: 0.8343923687934875\n",
      "Epoch [192/500], Loss: 0.8352007865905762\n",
      "Epoch [193/500], Loss: 0.8352946639060974\n",
      "Epoch [194/500], Loss: 0.8352434635162354\n",
      "Epoch [195/500], Loss: 0.8347834348678589\n",
      "Epoch [196/500], Loss: 0.8344097137451172\n",
      "Epoch [197/500], Loss: 0.8342053890228271\n",
      "Epoch [198/500], Loss: 0.834111213684082\n",
      "Epoch [199/500], Loss: 0.8344466686248779\n",
      "Epoch [200/500], Loss: 0.8347721099853516\n",
      "Epoch [201/500], Loss: 0.8349432349205017\n",
      "Epoch [202/500], Loss: 0.83390873670578\n",
      "Epoch [203/500], Loss: 0.8326729536056519\n",
      "Epoch [204/500], Loss: 0.8322118520736694\n",
      "Epoch [205/500], Loss: 0.8328704237937927\n",
      "Epoch [206/500], Loss: 0.833739697933197\n",
      "Epoch [207/500], Loss: 0.8338983654975891\n",
      "Epoch [208/500], Loss: 0.8336382508277893\n",
      "Epoch [209/500], Loss: 0.833220362663269\n",
      "Epoch [210/500], Loss: 0.8329614996910095\n",
      "Epoch [211/500], Loss: 0.8325457572937012\n",
      "Epoch [212/500], Loss: 0.8323056101799011\n",
      "Epoch [213/500], Loss: 0.8322896957397461\n",
      "Epoch [214/500], Loss: 0.8326228857040405\n",
      "Epoch [215/500], Loss: 0.8332626819610596\n",
      "Epoch [216/500], Loss: 0.8334786295890808\n",
      "Epoch [217/500], Loss: 0.8337112069129944\n",
      "Epoch [218/500], Loss: 0.8342498540878296\n",
      "Epoch [219/500], Loss: 0.835370659828186\n",
      "Epoch [220/500], Loss: 0.8357746005058289\n",
      "Epoch [221/500], Loss: 0.8351097106933594\n",
      "Epoch [222/500], Loss: 0.8356676697731018\n",
      "Epoch [223/500], Loss: 0.8359654545783997\n",
      "Epoch [224/500], Loss: 0.8338532447814941\n",
      "Epoch [225/500], Loss: 0.8318427205085754\n",
      "Epoch [226/500], Loss: 0.8317930698394775\n",
      "Epoch [227/500], Loss: 0.8326871991157532\n",
      "Epoch [228/500], Loss: 0.8337019085884094\n",
      "Epoch [229/500], Loss: 0.8344354033470154\n",
      "Epoch [230/500], Loss: 0.8336285352706909\n",
      "Epoch [231/500], Loss: 0.8327224850654602\n",
      "Epoch [232/500], Loss: 0.8314339518547058\n",
      "Epoch [233/500], Loss: 0.8307457566261292\n",
      "Epoch [234/500], Loss: 0.8313878178596497\n",
      "Epoch [235/500], Loss: 0.8324363231658936\n",
      "Epoch [236/500], Loss: 0.8327930569648743\n",
      "Epoch [237/500], Loss: 0.8325984477996826\n",
      "Epoch [238/500], Loss: 0.8324818015098572\n",
      "Epoch [239/500], Loss: 0.8312089443206787\n",
      "Epoch [240/500], Loss: 0.8302355408668518\n",
      "Epoch [241/500], Loss: 0.8305021524429321\n",
      "Epoch [242/500], Loss: 0.8313876390457153\n",
      "Epoch [243/500], Loss: 0.8322537541389465\n",
      "Epoch [244/500], Loss: 0.8319235444068909\n",
      "Epoch [245/500], Loss: 0.8313486576080322\n",
      "Epoch [246/500], Loss: 0.8304928541183472\n",
      "Epoch [247/500], Loss: 0.8299033045768738\n",
      "Epoch [248/500], Loss: 0.8299354314804077\n",
      "Epoch [249/500], Loss: 0.8301509022712708\n",
      "Epoch [250/500], Loss: 0.830337405204773\n",
      "Epoch [251/500], Loss: 0.8306620717048645\n",
      "Epoch [252/500], Loss: 0.8310120105743408\n",
      "Epoch [253/500], Loss: 0.8307315111160278\n",
      "Epoch [254/500], Loss: 0.8308426141738892\n",
      "Epoch [255/500], Loss: 0.8315483331680298\n",
      "Epoch [256/500], Loss: 0.8318960070610046\n",
      "Epoch [257/500], Loss: 0.8331197500228882\n",
      "Epoch [258/500], Loss: 0.8335056900978088\n",
      "Epoch [259/500], Loss: 0.8324926495552063\n",
      "Epoch [260/500], Loss: 0.8302291631698608\n",
      "Epoch [261/500], Loss: 0.8293947577476501\n",
      "Epoch [262/500], Loss: 0.8300243020057678\n",
      "Epoch [263/500], Loss: 0.8308398723602295\n",
      "Epoch [264/500], Loss: 0.8314815759658813\n",
      "Epoch [265/500], Loss: 0.8307955861091614\n",
      "Epoch [266/500], Loss: 0.8296840786933899\n",
      "Epoch [267/500], Loss: 0.8287844657897949\n",
      "Epoch [268/500], Loss: 0.8289600014686584\n",
      "Epoch [269/500], Loss: 0.8296035528182983\n",
      "Epoch [270/500], Loss: 0.8299111723899841\n",
      "Epoch [271/500], Loss: 0.8299055695533752\n",
      "Epoch [272/500], Loss: 0.8295655250549316\n",
      "Epoch [273/500], Loss: 0.8290023803710938\n",
      "Epoch [274/500], Loss: 0.8284599184989929\n",
      "Epoch [275/500], Loss: 0.8281895518302917\n",
      "Epoch [276/500], Loss: 0.8284404277801514\n",
      "Epoch [277/500], Loss: 0.828643798828125\n",
      "Epoch [278/500], Loss: 0.8288363814353943\n",
      "Epoch [279/500], Loss: 0.8290604948997498\n",
      "Epoch [280/500], Loss: 0.8292338848114014\n",
      "Epoch [281/500], Loss: 0.8293072581291199\n",
      "Epoch [282/500], Loss: 0.8289279937744141\n",
      "Epoch [283/500], Loss: 0.8284083008766174\n",
      "Epoch [284/500], Loss: 0.8281537890434265\n",
      "Epoch [285/500], Loss: 0.8282533288002014\n",
      "Epoch [286/500], Loss: 0.828676164150238\n",
      "Epoch [287/500], Loss: 0.8293517231941223\n",
      "Epoch [288/500], Loss: 0.8297333121299744\n",
      "Epoch [289/500], Loss: 0.8305549025535583\n",
      "Epoch [290/500], Loss: 0.8313572406768799\n",
      "Epoch [291/500], Loss: 0.8312233686447144\n",
      "Epoch [292/500], Loss: 0.8298178911209106\n",
      "Epoch [293/500], Loss: 0.828535795211792\n",
      "Epoch [294/500], Loss: 0.829078733921051\n",
      "Epoch [295/500], Loss: 0.8300135731697083\n",
      "Epoch [296/500], Loss: 0.8308995962142944\n",
      "Epoch [297/500], Loss: 0.8301544189453125\n",
      "Epoch [298/500], Loss: 0.8293973803520203\n",
      "Epoch [299/500], Loss: 0.8281682133674622\n",
      "Epoch [300/500], Loss: 0.8276198506355286\n",
      "Epoch [301/500], Loss: 0.8280998468399048\n",
      "Epoch [302/500], Loss: 0.8288893103599548\n",
      "Epoch [303/500], Loss: 0.8294999003410339\n",
      "Epoch [304/500], Loss: 0.8284765481948853\n",
      "Epoch [305/500], Loss: 0.8272076845169067\n",
      "Epoch [306/500], Loss: 0.8270771503448486\n",
      "Epoch [307/500], Loss: 0.8278557658195496\n",
      "Epoch [308/500], Loss: 0.8285075426101685\n",
      "Epoch [309/500], Loss: 0.8279339671134949\n",
      "Epoch [310/500], Loss: 0.8275479078292847\n",
      "Epoch [311/500], Loss: 0.8274352550506592\n",
      "Epoch [312/500], Loss: 0.8274109959602356\n",
      "Epoch [313/500], Loss: 0.8272655010223389\n",
      "Epoch [314/500], Loss: 0.82733553647995\n",
      "Epoch [315/500], Loss: 0.8278176188468933\n",
      "Epoch [316/500], Loss: 0.8275145888328552\n",
      "Epoch [317/500], Loss: 0.8267842531204224\n",
      "Epoch [318/500], Loss: 0.8262476921081543\n",
      "Epoch [319/500], Loss: 0.8262760043144226\n",
      "Epoch [320/500], Loss: 0.8270500302314758\n",
      "Epoch [321/500], Loss: 0.8279585838317871\n",
      "Epoch [322/500], Loss: 0.8284006118774414\n",
      "Epoch [323/500], Loss: 0.827958345413208\n",
      "Epoch [324/500], Loss: 0.8280623555183411\n",
      "Epoch [325/500], Loss: 0.8291085362434387\n",
      "Epoch [326/500], Loss: 0.8297411799430847\n",
      "Epoch [327/500], Loss: 0.8296360969543457\n",
      "Epoch [328/500], Loss: 0.8288841843605042\n",
      "Epoch [329/500], Loss: 0.8287624716758728\n",
      "Epoch [330/500], Loss: 0.8277356028556824\n",
      "Epoch [331/500], Loss: 0.8267965316772461\n",
      "Epoch [332/500], Loss: 0.8274829983711243\n",
      "Epoch [333/500], Loss: 0.8283352255821228\n",
      "Epoch [334/500], Loss: 0.8276762366294861\n",
      "Epoch [335/500], Loss: 0.8270342350006104\n",
      "Epoch [336/500], Loss: 0.8275067806243896\n",
      "Epoch [337/500], Loss: 0.8283640146255493\n",
      "Epoch [338/500], Loss: 0.8273050785064697\n",
      "Epoch [339/500], Loss: 0.82621830701828\n",
      "Epoch [340/500], Loss: 0.825829267501831\n",
      "Epoch [341/500], Loss: 0.8257331252098083\n",
      "Epoch [342/500], Loss: 0.826669454574585\n",
      "Epoch [343/500], Loss: 0.8268351554870605\n",
      "Epoch [344/500], Loss: 0.8264329433441162\n",
      "Epoch [345/500], Loss: 0.8252395391464233\n",
      "Epoch [346/500], Loss: 0.8250262141227722\n",
      "Epoch [347/500], Loss: 0.825264036655426\n",
      "Epoch [348/500], Loss: 0.8253676295280457\n",
      "Epoch [349/500], Loss: 0.8254508376121521\n",
      "Epoch [350/500], Loss: 0.8248223662376404\n",
      "Epoch [351/500], Loss: 0.8243048191070557\n",
      "Epoch [352/500], Loss: 0.8242785930633545\n",
      "Epoch [353/500], Loss: 0.8248716592788696\n",
      "Epoch [354/500], Loss: 0.8257256150245667\n",
      "Epoch [355/500], Loss: 0.8258028030395508\n",
      "Epoch [356/500], Loss: 0.8267365097999573\n",
      "Epoch [357/500], Loss: 0.8278952240943909\n",
      "Epoch [358/500], Loss: 0.8285052180290222\n",
      "Epoch [359/500], Loss: 0.8263825178146362\n",
      "Epoch [360/500], Loss: 0.8247390985488892\n",
      "Epoch [361/500], Loss: 0.8247605562210083\n",
      "Epoch [362/500], Loss: 0.8259850740432739\n",
      "Epoch [363/500], Loss: 0.8260003924369812\n",
      "Epoch [364/500], Loss: 0.8246972560882568\n",
      "Epoch [365/500], Loss: 0.823806881904602\n",
      "Epoch [366/500], Loss: 0.8239974975585938\n",
      "Epoch [367/500], Loss: 0.8248432874679565\n",
      "Epoch [368/500], Loss: 0.8251853585243225\n",
      "Epoch [369/500], Loss: 0.8247107267379761\n",
      "Epoch [370/500], Loss: 0.8239562511444092\n",
      "Epoch [371/500], Loss: 0.8234345316886902\n",
      "Epoch [372/500], Loss: 0.8236212730407715\n",
      "Epoch [373/500], Loss: 0.8245000839233398\n",
      "Epoch [374/500], Loss: 0.8249141573905945\n",
      "Epoch [375/500], Loss: 0.8249905705451965\n",
      "Epoch [376/500], Loss: 0.8243004083633423\n",
      "Epoch [377/500], Loss: 0.8241349458694458\n",
      "Epoch [378/500], Loss: 0.824928343296051\n",
      "Epoch [379/500], Loss: 0.8262166380882263\n",
      "Epoch [380/500], Loss: 0.8273764848709106\n",
      "Epoch [381/500], Loss: 0.8266717791557312\n",
      "Epoch [382/500], Loss: 0.8252503275871277\n",
      "Epoch [383/500], Loss: 0.8240342736244202\n",
      "Epoch [384/500], Loss: 0.8237536549568176\n",
      "Epoch [385/500], Loss: 0.8248196244239807\n",
      "Epoch [386/500], Loss: 0.8249720335006714\n",
      "Epoch [387/500], Loss: 0.8245993256568909\n",
      "Epoch [388/500], Loss: 0.823807418346405\n",
      "Epoch [389/500], Loss: 0.8236481547355652\n",
      "Epoch [390/500], Loss: 0.8241956830024719\n",
      "Epoch [391/500], Loss: 0.8240981101989746\n",
      "Epoch [392/500], Loss: 0.8236387372016907\n",
      "Epoch [393/500], Loss: 0.8229239583015442\n",
      "Epoch [394/500], Loss: 0.8228240609169006\n",
      "Epoch [395/500], Loss: 0.8229478597640991\n",
      "Epoch [396/500], Loss: 0.8231523633003235\n",
      "Epoch [397/500], Loss: 0.8229702115058899\n",
      "Epoch [398/500], Loss: 0.8224911093711853\n",
      "Epoch [399/500], Loss: 0.8221991062164307\n",
      "Epoch [400/500], Loss: 0.8221983313560486\n",
      "Epoch [401/500], Loss: 0.8227307200431824\n",
      "Epoch [402/500], Loss: 0.824002206325531\n",
      "Epoch [403/500], Loss: 0.8246934413909912\n",
      "Epoch [404/500], Loss: 0.8257024884223938\n",
      "Epoch [405/500], Loss: 0.8258519172668457\n",
      "Epoch [406/500], Loss: 0.8253421783447266\n",
      "Epoch [407/500], Loss: 0.8246545195579529\n",
      "Epoch [408/500], Loss: 0.8235934376716614\n",
      "Epoch [409/500], Loss: 0.8226837515830994\n",
      "Epoch [410/500], Loss: 0.8218943476676941\n",
      "Epoch [411/500], Loss: 0.8219695091247559\n",
      "Epoch [412/500], Loss: 0.8228223323822021\n",
      "Epoch [413/500], Loss: 0.8233975172042847\n",
      "Epoch [414/500], Loss: 0.823107898235321\n",
      "Epoch [415/500], Loss: 0.8217737674713135\n",
      "Epoch [416/500], Loss: 0.8212680220603943\n",
      "Epoch [417/500], Loss: 0.8217219114303589\n",
      "Epoch [418/500], Loss: 0.822780966758728\n",
      "Epoch [419/500], Loss: 0.8237792253494263\n",
      "Epoch [420/500], Loss: 0.8225211501121521\n",
      "Epoch [421/500], Loss: 0.8211870193481445\n",
      "Epoch [422/500], Loss: 0.8210849761962891\n",
      "Epoch [423/500], Loss: 0.8219581246376038\n",
      "Epoch [424/500], Loss: 0.822526752948761\n",
      "Epoch [425/500], Loss: 0.8216887712478638\n",
      "Epoch [426/500], Loss: 0.8209023475646973\n",
      "Epoch [427/500], Loss: 0.8210527896881104\n",
      "Epoch [428/500], Loss: 0.8218519687652588\n",
      "Epoch [429/500], Loss: 0.8223173022270203\n",
      "Epoch [430/500], Loss: 0.8219456076622009\n",
      "Epoch [431/500], Loss: 0.8212055563926697\n",
      "Epoch [432/500], Loss: 0.8208227753639221\n",
      "Epoch [433/500], Loss: 0.8207482695579529\n",
      "Epoch [434/500], Loss: 0.8208391070365906\n",
      "Epoch [435/500], Loss: 0.8209059238433838\n",
      "Epoch [436/500], Loss: 0.8210756778717041\n",
      "Epoch [437/500], Loss: 0.8213449120521545\n",
      "Epoch [438/500], Loss: 0.8215005397796631\n",
      "Epoch [439/500], Loss: 0.8218934535980225\n",
      "Epoch [440/500], Loss: 0.8223350644111633\n",
      "Epoch [441/500], Loss: 0.8232773542404175\n",
      "Epoch [442/500], Loss: 0.822691798210144\n",
      "Epoch [443/500], Loss: 0.8224455118179321\n",
      "Epoch [444/500], Loss: 0.8221849799156189\n",
      "Epoch [445/500], Loss: 0.8223659992218018\n",
      "Epoch [446/500], Loss: 0.8222701549530029\n",
      "Epoch [447/500], Loss: 0.8212670087814331\n",
      "Epoch [448/500], Loss: 0.8197631239891052\n",
      "Epoch [449/500], Loss: 0.8198558688163757\n",
      "Epoch [450/500], Loss: 0.8213314414024353\n",
      "Epoch [451/500], Loss: 0.8226597309112549\n",
      "Epoch [452/500], Loss: 0.8224326968193054\n",
      "Epoch [453/500], Loss: 0.8215816617012024\n",
      "Epoch [454/500], Loss: 0.8202975392341614\n",
      "Epoch [455/500], Loss: 0.8195735812187195\n",
      "Epoch [456/500], Loss: 0.8205627799034119\n",
      "Epoch [457/500], Loss: 0.8221598267555237\n",
      "Epoch [458/500], Loss: 0.8227481842041016\n",
      "Epoch [459/500], Loss: 0.821252703666687\n",
      "Epoch [460/500], Loss: 0.8192947506904602\n",
      "Epoch [461/500], Loss: 0.8197569251060486\n",
      "Epoch [462/500], Loss: 0.8215067982673645\n",
      "Epoch [463/500], Loss: 0.8225821256637573\n",
      "Epoch [464/500], Loss: 0.8213178515434265\n",
      "Epoch [465/500], Loss: 0.8194060921669006\n",
      "Epoch [466/500], Loss: 0.8197931051254272\n",
      "Epoch [467/500], Loss: 0.8202550411224365\n",
      "Epoch [468/500], Loss: 0.820588231086731\n",
      "Epoch [469/500], Loss: 0.8200598359107971\n",
      "Epoch [470/500], Loss: 0.8195117712020874\n",
      "Epoch [471/500], Loss: 0.8194276690483093\n",
      "Epoch [472/500], Loss: 0.8191938400268555\n",
      "Epoch [473/500], Loss: 0.8196308016777039\n",
      "Epoch [474/500], Loss: 0.8197996020317078\n",
      "Epoch [475/500], Loss: 0.8193778991699219\n",
      "Epoch [476/500], Loss: 0.8185892105102539\n",
      "Epoch [477/500], Loss: 0.8184547424316406\n",
      "Epoch [478/500], Loss: 0.8192211389541626\n",
      "Epoch [479/500], Loss: 0.8196051716804504\n",
      "Epoch [480/500], Loss: 0.8189902901649475\n",
      "Epoch [481/500], Loss: 0.8180840015411377\n",
      "Epoch [482/500], Loss: 0.8181883096694946\n",
      "Epoch [483/500], Loss: 0.8190566301345825\n",
      "Epoch [484/500], Loss: 0.8193250298500061\n",
      "Epoch [485/500], Loss: 0.8187856078147888\n",
      "Epoch [486/500], Loss: 0.8183168768882751\n",
      "Epoch [487/500], Loss: 0.8188192844390869\n",
      "Epoch [488/500], Loss: 0.8196654915809631\n",
      "Epoch [489/500], Loss: 0.8195917010307312\n",
      "Epoch [490/500], Loss: 0.8192249536514282\n",
      "Epoch [491/500], Loss: 0.8187969923019409\n",
      "Epoch [492/500], Loss: 0.8191862106323242\n",
      "Epoch [493/500], Loss: 0.8190565705299377\n",
      "Epoch [494/500], Loss: 0.8184361457824707\n",
      "Epoch [495/500], Loss: 0.8176470398902893\n",
      "Epoch [496/500], Loss: 0.8175796866416931\n",
      "Epoch [497/500], Loss: 0.8179395198822021\n",
      "Epoch [498/500], Loss: 0.8177878856658936\n",
      "Epoch [499/500], Loss: 0.8170930743217468\n",
      "Epoch [500/500], Loss: 0.8168686032295227\n"
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "num_epochs = 500\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(Xtrain) #Prediction\n",
    "    loss = criterion(outputs, Ytrain) #Loss calculation\n",
    "\n",
    "    optimizer.zero_grad() #reset optimizer gradient\n",
    "    loss.backward() # bak√•t ?\n",
    "    optimizer.step() # uppdatera vikter\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6101485148514851\n"
     ]
    }
   ],
   "source": [
    "# PRINT ACCURACY\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs_test = model(Xtest)\n",
    "    predicted_labels = torch.argmax(outputs_test, dim=1)\n",
    "    acc = torch.sum(predicted_labels == Ytest).item() / len(Ytest)\n",
    "    print(f\"Test Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model weights here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Linusenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
