{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import socket\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from ipwhois import IPWhois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reads the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets directly from Netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"../../project_course_data/\"\n",
    "fileName = \"owndata.txt\"\n",
    "\n",
    "with open(filePath + fileName, \"r\") as f:\n",
    "    content = f.read().replace(\"->\", \" \").replace(\" K \", \"K \").replace(\" M \", \"M \").replace(\" G \", \"G \")\n",
    "    \n",
    "csvStringIO = io.StringIO(content)\n",
    "columnNames = [\"Datetime\", \"Time\", \"Duration\",  \"Proto\", \"Src IP Addr:Port\", \"Dst IP Addr:Port\", \"Packets\", \"Bytes\", \"Flows\"]\n",
    "\n",
    "# dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f')\n",
    "\n",
    "data = pd.read_csv(csvStringIO, sep = '\\s+', names = columnNames, header = None, usecols=range(len(columnNames)), parse_dates=True, engine = \"python\")\n",
    "data = data.iloc[1:-4] #Removes the summary lines and col names\n",
    "\n",
    "data[\"Datetime\"] += \" \" + data[\"Time\"]\n",
    "data = data.drop(columns = [\"Time\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SORTING AND SPLITTING AND COMBINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Convert the datetime column to pandas datetime format\n",
    "data['Datetime'] = pd.to_datetime(data['Datetime'])\n",
    "\n",
    "# Sort the DataFrame by the datetime column\n",
    "data = data.sort_values(by='Datetime')\n",
    "\n",
    "# Split IP address and port to two columns, and drops the old column\n",
    "data[['Src IP Addr', 'Src Port']] = data['Src IP Addr:Port'].str.split(':', n=1, expand=True)\n",
    "data[['Dst IP Addr', 'Dst Port']] = data['Dst IP Addr:Port'].str.split(':', n=1, expand=True)\n",
    "data = data.drop(columns=[\"Src IP Addr:Port\", \"Dst IP Addr:Port\"])\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes Duration column to float\n",
    "data['Duration'] = data['Duration'].astype(float)\n",
    "# Drop outliers\n",
    "data = data.drop(data[data.Duration > 10000].index)\n",
    "\n",
    "# Find clients IP address\n",
    "client = data['Src IP Addr'].value_counts().idxmax().split('.')\n",
    "client = '.'.join(client[:3])\n",
    "\n",
    "# Initialize 'Host IP'-column from 'Src Ip Addr'\n",
    "data['Host IP'] = data['Src IP Addr']\n",
    "data['Client IP'] = data['Dst IP Addr']\n",
    "\n",
    "# Removes all internal flows\n",
    "# If the destination IP is not equal to the clients IP, adds it to 'Host IP'-column\n",
    "for index, row in data.iterrows():\n",
    "    if client in row['Dst IP Addr'] and client in row['Src IP Addr']:\n",
    "        data.drop(index, inplace=True)\n",
    "    elif client not in row['Dst IP Addr']:\n",
    "        data.at[index, 'Host IP'] = row['Dst IP Addr']\n",
    "        data.at[index, 'Client IP'] = row['Src IP Addr']\n",
    "data = data.reset_index(drop=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prefix processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bytes(value):\n",
    "    multipliers = {'K': 1000, 'M': 1000000, 'G': 1000000000}\n",
    "\n",
    "    # Split the value into numerical part and prefix (if present)\n",
    "    parts = re.split(r'(\\d+)', value)\n",
    "    parts = [item for item in parts if item]\n",
    "    num_part = float(parts[0]) #if parts[0].isdigit() else None\n",
    "    prefix = parts[1] if len(parts) > 1 else None\n",
    "\n",
    "    # Check if a valid prefix is present\n",
    "    if prefix and prefix in multipliers:\n",
    "        return num_part * multipliers[prefix]\n",
    "    elif num_part is not None:\n",
    "        # If no valid prefix is found but there is a numerical part, return it as is\n",
    "        return num_part\n",
    "    else:\n",
    "        # If neither numerical part nor valid prefix is found, return the original value\n",
    "        return float(value)\n",
    "\n",
    "# Apply the conversion function to the 'Bytes' column\n",
    "data['Bytes'] = data['Bytes'].apply(convert_bytes)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse DNS-lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all unique addresses\n",
    "unique_ip = data['Host IP'].unique()\n",
    "\n",
    "# Creates a new dataframe\n",
    "data_DNS = pd.DataFrame(columns=['IP', 'Host'])\n",
    "\n",
    "data_DNS['IP']=unique_ip\n",
    "host = []\n",
    "\n",
    "# for-loop for doing reverse DNS lookup\n",
    "i=0\n",
    "for ip in unique_ip:\n",
    "    try:\n",
    "        host_name = socket.gethostbyaddr(ip)[0]\n",
    "        host.append(host_name)\n",
    "    except socket.herror:\n",
    "        host.append(None)\n",
    "    \n",
    "    if i % 100 == 0: # Used to keep track how far along we've come\n",
    "        print(f\"{i} / {len(unique_ip)}\")\n",
    "    i += 1\n",
    "\n",
    "# Adds the corresponding domain names to the IP-addresses and creates a CSV-file\n",
    "data_DNS['Host'] = host\n",
    "# data_DNS.to_csv('./host_names', index=False)\n",
    "    \n",
    "print(data_DNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNS_dict = {}\n",
    "for index, row in data_DNS.iterrows():\n",
    "    DNS_dict[row[\"IP\"]] = row[\"Host\"]\n",
    "\n",
    "print(DNS_dict)\n",
    "\n",
    "\n",
    "dataWithDomains = data.copy()\n",
    "dataWithDomains[\"Domain Name\"] = dataWithDomains.apply(lambda row: DNS_dict[row[\"Host IP\"]], axis= 1)\n",
    "\n",
    "print(dataWithDomains)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changes Protocol into feature-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithDummies = dataWithDomains.copy()\n",
    "\n",
    "# Get the dummies and store it in a variable\n",
    "dummies = pd.get_dummies(dataWithDummies.Proto).astype(int)\n",
    " \n",
    "# Concatenate the dummies to original dataframe\n",
    "dataWithDummies = pd.concat([dataWithDummies, dummies], axis='columns')\n",
    "\n",
    "# drop the values\n",
    "dataWithDummies = dataWithDummies.drop(['Proto'], axis='columns')\n",
    "dataWithDummies = dataWithDummies.fillna('0')\n",
    "\n",
    "print(dataWithDummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change PORT into feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creates a column for non-client ports\n",
    "dataWithDummies['Host Port'] = None\n",
    "\n",
    "# Adds the non-client port to the new column by checking that the ports (Src & Dst) does not contain the client IP\n",
    "for index, row in dataWithDummies.iterrows():\n",
    "    if row[\"Host IP\"] ==  row['Src IP Addr']:\n",
    "        dataWithDummies.at[index, 'Host Port'] = row['Src Port']\n",
    "    else:\n",
    "        dataWithDummies.at[index, 'Host Port'] = row['Dst Port'] \n",
    "\n",
    "# Get the dummies and store it in a variable\n",
    "dummies = pd.get_dummies(dataWithDummies[\"Host Port\"]).astype(int)\n",
    " \n",
    "# Concatenate the dummies to original dataframe\n",
    "dataWithDummies = pd.concat([dataWithDummies, dummies], axis='columns')\n",
    "\n",
    "# drop the values\n",
    "dataWithDummies = dataWithDummies.fillna('0')\n",
    "\n",
    "print(dataWithDummies)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BAG OF WORDS FOR THE DOMAIN NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithBOW = dataWithDummies.copy()\n",
    "\n",
    "# Create and fit vectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "X = vectorizer.fit_transform(dataWithBOW['Domain Name'])\n",
    "\n",
    "# vectorize\n",
    "df_bow = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "# find columns with only numeric names and drop them\n",
    "numeric_columns = df_bow.columns[df_bow.columns.str.isnumeric()]\n",
    "df_bow.drop(numeric_columns, axis=1, inplace=True)\n",
    "\n",
    "dataWithBOW.reset_index(drop=True, inplace=True)\n",
    "df_bow.reset_index(drop=True, inplace=True)\n",
    "dataWithBOW = pd.concat([dataWithBOW, df_bow], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CERTIFICATE LOOKUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHOIS FETCH FUNCTION\n",
    "def get_ip_info(ip):\n",
    "    \n",
    "    ipwhois_obj = IPWhois(ip)\n",
    "\n",
    "    result = ipwhois_obj.lookup_rdap()\n",
    "\n",
    "    # Available information from ipwhois:\n",
    "\n",
    "    # print(\"IP Address:\", result['query'])\n",
    "    # print(\"ASN:\", result['asn'])\n",
    "    # print(\"CIDR:\", result['asn_cidr'])\n",
    "    # print(\"Name:\", result['network']['name'])\n",
    "    # print(\"Country:\", result['asn_country_code'])\n",
    "    # print(\"Description:\", result['asn_description'])\n",
    "\n",
    "    return {\"name\": result['network']['name'], \"country\": result['asn_country_code']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithWhoIs = dataWithBOW.copy()\n",
    "\n",
    "sz = len(dataWithWhoIs)\n",
    "t = 0\n",
    "memo = {}\n",
    "## ITERATING THROUGH DATASET / CERTIFICATE LOOKUP OF IP\n",
    "for index, row in dataWithWhoIs.iterrows():\n",
    "\n",
    "    host_IP = row[\"Host IP\"]\n",
    "\n",
    "    if(host_IP not in memo): # NEW IP\n",
    "        print(\"not in\")\n",
    "        try: \n",
    "            # fetch ipwhois info\n",
    "            whoIsResult = get_ip_info(row[\"Host IP\"])\n",
    "\n",
    "            # add info\n",
    "            dataWithWhoIs.at[index, \"ipwhois_name\"] = whoIsResult[\"name\"]\n",
    "            dataWithWhoIs.at[index, \"ipwhois_country\"] = whoIsResult[\"country\"]\n",
    "\n",
    "            # save for later\n",
    "            memo[host_IP] = whoIsResult\n",
    "\n",
    "        except:\n",
    "            # default option\n",
    "            dataWithWhoIs.at[index, \"ipwhois_name\"] = np.nan\n",
    "            dataWithWhoIs.at[index, \"ipwhois_country\"] = np.nan\n",
    "\n",
    "    else: # IP ALREADY CHECKED\n",
    "        # get saved whois info\n",
    "        whoIsResult = memo[host_IP]\n",
    "\n",
    "        # add info\n",
    "        dataWithWhoIs.at[index, \"ipwhois_name\"] = whoIsResult[\"name\"]\n",
    "        dataWithWhoIs.at[index, \"ipwhois_country\"] = whoIsResult[\"country\"]\n",
    "\n",
    "    t+=1\n",
    "    \n",
    "    print(f\"{t} / {sz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE DUMMIES FROM WHOIS DATA\n",
    "\n",
    "# get the dummies and store it in a variable\n",
    "dummies_name = pd.get_dummies(dataWithWhoIs.ipwhois_name).astype(int)\n",
    "dummies_country = pd.get_dummies(dataWithWhoIs.ipwhois_country).astype(int)\n",
    "\n",
    " \n",
    "# Concatenate the dummies to original dataframe\n",
    "dataWithWhoIs = pd.concat([dataWithWhoIs, dummies_name], axis='columns')\n",
    "dataWithWhoIs = pd.concat([dataWithWhoIs, dummies_country], axis='columns')\n",
    "\n",
    "\n",
    "# drop the values\n",
    "dataWithWhoIs = dataWithWhoIs.drop([\"ipwhois_name\", \"ipwhois_country\"], axis='columns')\n",
    "dataWithWhoIs = dataWithWhoIs.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAVE TO FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFileName = \"preprocessedData.csv\"\n",
    "dataWithWhoIs.to_csv(filePath + newFileName, sep=\"\\t\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Linusenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
